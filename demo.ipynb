{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this demo, we will demostrate how to fine-tune a pre-trained model to do text classification."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Sample Data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "sample_data = pd.read_csv('data/train.csv')[['full_text', 'cohesion']]\n",
        "sample_data.columns = ['text', 'label']\n",
        "sample_data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_pandas(sample_data, preserve_index=False) \n",
        "dataset = dataset.train_test_split(test_size=0.3) \n",
        "dataset"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune the Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import  AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-cased')\n",
        "\n",
        "def tokenize_function(data):\n",
        "    return tokenizer(data[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)  \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-cased\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics Function\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
        "    return {\"rmse\": rmse}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
        "                                  logging_strategy=\"epoch\",\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  per_device_train_batch_size=16,\n",
        "                                  per_device_eval_batch_size=16,\n",
        "                                  num_train_epochs=3,\n",
        "                                  save_total_limit = 2,\n",
        "                                  save_strategy = 'no',\n",
        "                                  load_best_model_at_end=False\n",
        "                                  )\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.train()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Load the Model and Tokenizer"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model/tokenizer\r\n",
        "model.save_pretrained(\"model\")\r\n",
        "tokenizer.save_pretrained(\"tokenizer\")\r\n",
        "\r\n",
        "# load the model/tokenizer\r\n",
        "from transformers import AutoModelForTokenClassification\r\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"model\")\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"tokenizer\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use the Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\r\n",
        "\r\n",
        "trainer = Trainer(model=model)\r\n",
        "\r\n",
        "\r\n",
        "def pipeline_prediction(text):\r\n",
        "    df=pd.DataFrame({'text':[text]})\r\n",
        "    dataset = Dataset.from_pandas(df,preserve_index=False) \r\n",
        "    tokenized_datasets = dataset.map(tokenize_function)\r\n",
        "    raw_pred, _, _ = trainer.predict(tokenized_datasets) \r\n",
        "    return(raw_pred[0][0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pred, labels, metrics = trainer.predict(tokenized_datasets['test'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pred"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "hugginface",
      "language": "python",
      "display_name": "huggingface"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "517cea473c5ce1aa4e49ae52e21d9e9cce00c6c77d79a2df75f1652a9c267de7"
      }
    },
    "kernel_info": {
      "name": "hugginface"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}